{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Luciano\\Salt\\env\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "import data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "it=iter(data.train_loader)\n",
    "real_batch = next(iter(it))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cinn = model.MNIST_cINN(5e-4)\n",
    "cinn.cuda()\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(cinn.optimizer, milestones=[20, 40], gamma=0.1)\n",
    "\n",
    "N_epochs = 60\n",
    "t_start = time()\n",
    "nll_mean = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch\tBatch/Total \tTime \tNLL train\tNLL val\tLR\n",
      "000 \t00000/00230 \t0.11 \t0.538928\t0.176847\t5.00e-04\n",
      "000 \t00050/00230 \t0.19 \t-0.666140\t-1.340032\t5.00e-04\n",
      "000 \t00100/00230 \t0.27 \t-1.241935\t-1.522886\t5.00e-04\n",
      "000 \t00150/00230 \t0.35 \t-1.317406\t-1.620022\t5.00e-04\n",
      "000 \t00200/00230 \t0.42 \t-1.351816\t-1.631858\t5.00e-04\n",
      "001 \t00000/00230 \t0.53 \t-1.364375\t-1.669222\t5.00e-04\n",
      "001 \t00050/00230 \t0.61 \t-1.387519\t-1.677190\t5.00e-04\n",
      "001 \t00100/00230 \t0.68 \t-1.398561\t-1.703947\t5.00e-04\n",
      "001 \t00150/00230 \t0.75 \t-1.411586\t-1.711710\t5.00e-04\n",
      "001 \t00200/00230 \t0.83 \t-1.419027\t-1.744163\t5.00e-04\n",
      "002 \t00000/00230 \t0.93 \t-1.423610\t-1.752489\t5.00e-04\n",
      "002 \t00050/00230 \t1.01 \t-1.437380\t-1.748425\t5.00e-04\n",
      "002 \t00100/00230 \t1.08 \t-1.446082\t-1.767792\t5.00e-04\n",
      "002 \t00150/00230 \t1.16 \t-1.451494\t-1.781033\t5.00e-04\n",
      "002 \t00200/00230 \t1.23 \t-1.457667\t-1.790701\t5.00e-04\n",
      "003 \t00000/00230 \t1.33 \t-1.461937\t-1.790992\t5.00e-04\n",
      "003 \t00050/00230 \t1.41 \t-1.473144\t-1.803693\t5.00e-04\n",
      "003 \t00100/00230 \t1.48 \t-1.477325\t-1.806622\t5.00e-04\n",
      "003 \t00150/00230 \t1.55 \t-1.479349\t-1.822212\t5.00e-04\n",
      "003 \t00200/00230 \t1.62 \t-1.483668\t-1.819627\t5.00e-04\n",
      "004 \t00000/00230 \t1.73 \t-1.485625\t-1.814607\t5.00e-04\n",
      "004 \t00050/00230 \t1.80 \t-1.496950\t-1.832733\t5.00e-04\n",
      "004 \t00100/00230 \t1.87 \t-1.499094\t-1.831534\t5.00e-04\n",
      "004 \t00150/00230 \t1.95 \t-1.499832\t-1.844814\t5.00e-04\n",
      "004 \t00200/00230 \t2.02 \t-1.505223\t-1.856484\t5.00e-04\n",
      "005 \t00000/00230 \t2.14 \t-1.506139\t-1.850253\t5.00e-04\n",
      "005 \t00050/00230 \t2.21 \t-1.515607\t-1.860036\t5.00e-04\n",
      "005 \t00100/00230 \t2.29 \t-1.515358\t-1.856443\t5.00e-04\n",
      "005 \t00150/00230 \t2.37 \t-1.519494\t-1.866169\t5.00e-04\n",
      "005 \t00200/00230 \t2.45 \t-1.519188\t-1.863500\t5.00e-04\n",
      "006 \t00000/00230 \t2.57 \t-1.521808\t-1.864371\t5.00e-04\n",
      "006 \t00050/00230 \t2.64 \t-1.530000\t-1.864608\t5.00e-04\n",
      "006 \t00100/00230 \t2.73 \t-1.532622\t-1.875403\t5.00e-04\n",
      "006 \t00150/00230 \t2.81 \t-1.532834\t-1.880521\t5.00e-04\n"
     ]
    }
   ],
   "source": [
    "print('Epoch\\tBatch/Total \\tTime \\tNLL train\\tNLL val\\tLR')\n",
    "for epoch in range(N_epochs):\n",
    "    for i, (x, l) in enumerate(data.train_loader): #data.train_loader):\n",
    "        x, l = x.cuda(), l.cuda()\n",
    "        z, log_j = cinn(x, l)\n",
    "\n",
    "        nll = torch.mean(z**2) / 2 - torch.mean(log_j) / model.ndim_total\n",
    "        nll.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(cinn.trainable_parameters, 10.)\n",
    "        nll_mean.append(nll.item())\n",
    "        cinn.optimizer.step()\n",
    "        cinn.optimizer.zero_grad()\n",
    "\n",
    "        if not i % 50:\n",
    "            with torch.no_grad():\n",
    "                z, log_j = cinn(data.val_x, data.val_l) #cinn(data.val_x, data.val_l)\n",
    "                nll_val = torch.mean(z**2) / 2 - torch.mean(log_j) / model.ndim_total\n",
    "\n",
    "            print('%.3i \\t%.5i/%.5i \\t%.2f \\t%.6f\\t%.6f\\t%.2e' % (epoch,\n",
    "                                                            i, len(data.train_loader),\n",
    "                                                            (time() - t_start)/60.,\n",
    "                                                            np.mean(nll_mean),\n",
    "                                                            nll_val.item(),\n",
    "                                                            cinn.optimizer.param_groups[0]['lr'],\n",
    "                                                            ), flush=True)\n",
    "            nll_mean = []\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cinn.state_dict(), 'output/mnist_cinn.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14f7fd295da18d51ca88726a263299245f27ba416687bfd4eada1f307496d378"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
