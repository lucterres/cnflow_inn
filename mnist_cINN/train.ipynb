{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "from torch.nn.functional import avg_pool2d, interpolate\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import config as c\n",
    "import opts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opts.parse(sys.argv)\n",
    "config_str = \"\"\n",
    "config_str += \"===\"*30 + \"\\n\"\n",
    "config_str += \"Config options:\\n\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Config options:\n",
      "\n",
      "  add_image_noise          \t0.15\n",
      "  batch_size               \t512\n",
      "  betas                    \t(0.9, 0.999)\n",
      "  checkpoint_on_error      \tTrue\n",
      "  checkpoint_save_interval \t360\n",
      "  checkpoint_save_overwrite\tTrue\n",
      "  clamping                 \t1.9\n",
      "  colorize                 \tFalse\n",
      "  cond_net_file            \t\n",
      "  cond_width               \t64\n",
      "  data_mean                \t0.0\n",
      "  data_std                 \t1.0\n",
      "  decay_by                 \t0.01\n",
      "  do_fwd                   \tTrue\n",
      "  do_rev                   \tFalse\n",
      "  fc_dropout               \t0.0\n",
      "  filename                 \toutput/saving_mnist_cinn.pt\n",
      "  img_dims                 \t(28, 28)\n",
      "  init_scale               \t0.03\n",
      "  internal_width           \t256\n",
      "  internal_width_conv      \t64\n",
      "  live_visualization       \tFalse\n",
      "  load_file                \t\n",
      "  loss_names               \t['L', 'L_rev']\n",
      "  lr                       \t0.0001\n",
      "  n_blocks                 \t7\n",
      "  n_blocks_conv            \t3\n",
      "  n_epochs                 \t1440\n",
      "  n_its_per_epoch          \t65536\n",
      "  output_dim               \t784\n",
      "  pre_low_lr               \t1\n",
      "  preview_upscale          \t3\n",
      "  progress_bar             \tTrue\n",
      "  sampling_temperature     \t0.8\n",
      "  weight_decay             \t1e-05\n",
      "==========================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for v in dir(c):\n",
    "    if v[0]=='_': continue\n",
    "    s=eval('c.%s'%(v))\n",
    "    config_str += \"  {:25}\\t{}\\n\".format(v,s)\n",
    "\n",
    "config_str += \"===\"*30 + \"\\n\"\n",
    "\n",
    "print(config_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "c.colorize=False"
=======
    "#c.colorize=True\n",
    "c.colorize"
>>>>>>> e1d4c5ad07df0090d2519240428a6de67e67fefb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
=======
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\simbr-env\\Miniconda\\envs\\salt\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
>>>>>>> e1d4c5ad07df0090d2519240428a6de67e67fefb
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch\t\tL\t\tL_rev\n"
     ]
    }
   ],
   "source": [
    "import model\n",
    "import data\n",
    "import viz\n",
    "import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if c.colorize:\n",
    "    import cond_net\n",
    "\n",
    "class dummy_loss(object):\n",
    "    def item(self):\n",
    "        return 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if c.load_file:\n",
    "    model.load(c.load_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_outputs(sigma):\n",
    "    return sigma * torch.cuda.FloatTensor(c.batch_size, c.output_dim).normal_()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.colorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000\t\t0.0000\t\t1.0000                                                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001\t\t0.0000\t\t1.0000                                                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "002\t\t-28.8071\t\t1.0000                                                            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003\t\t-139.6184\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "004\t\t-312.7874\t\t1.0000                                                           \n"
=======
      "002\t\t-29.5028\t\t1.0000                                                            \n"
>>>>>>> e1d4c5ad07df0090d2519240428a6de67e67fefb
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
<<<<<<< HEAD
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-7de708a4b761>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0ml_rev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdummy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             \u001b[0mloss_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml_rev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Luciano\\_0PH\\Code\\ConditionalNFlow\\cnflow_inn\\mnist_cINN\\model.py\u001b[0m in \u001b[0;36moptim_step\u001b[1;34m()\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0moptim_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Luciano\\Salt\\env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Luciano\\Salt\\env\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Luciano\\Salt\\env\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Luciano\\Salt\\env\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    105\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             F.adam(params_with_grad,\n\u001b[0m\u001b[0;32m    108\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Luciano\\Salt\\env\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
=======
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003\t\t-141.5633\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "004\t\t-312.4865\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "005\t\t-400.3436\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "006\t\t-460.5282\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "007\t\t-504.2522\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "008\t\t-539.1761\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "009\t\t-567.5555\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "010\t\t-591.5207\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "011\t\t-611.9165\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "012\t\t-629.7160\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "013\t\t-644.7872\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "014\t\t-657.7227\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "015\t\t-668.8634\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "016\t\t-678.0444\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "017\t\t-686.0782\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "018\t\t-692.1334\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "019\t\t-697.7762\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "020\t\t-702.3009\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "021\t\t-706.0868\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "022\t\t-709.5644\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "023\t\t-712.4119\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "024\t\t-714.9066\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "025\t\t-717.0569\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "026\t\t-719.2235\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "027\t\t-721.0599\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "028\t\t-723.0547\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "029\t\t-724.7388\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "030\t\t-726.5212\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 0/117 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "031\t\t-728.4769\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "032\t\t-730.3992\t\t1.0000                                                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|█████████████████████████████████████▌      | 100/117 [00:07<00:01, 15.33it/s]"
>>>>>>> e1d4c5ad07df0090d2519240428a6de67e67fefb
     ]
    }
   ],
   "source": [
    "if c.colorize:\n",
    "    cond_tensor = torch.zeros(c.batch_size, model.cond_size, *c.img_dims).cuda()\n",
    "\n",
    "    def make_cond(mask, cond_features):\n",
    "        cond_tensor[:, 0] = mask[:, 0]\n",
    "        cond_tensor[:, 1:] = cond_features.view(c.batch_size, -1, 1, 1).expand(-1, -1, *c.img_dims)\n",
    "        return cond_tensor\n",
    "\n",
    "else:\n",
    "    cond_tensor = torch.zeros(c.batch_size, model.cond_size).cuda()\n",
    "    def make_cond(labels):\n",
    "        cond_tensor.zero_()\n",
    "        cond_tensor.scatter_(1, labels.view(-1,1), 1.)\n",
    "        return cond_tensor\n",
    "\n",
    "    test_labels = torch.LongTensor((list(range(10))*(c.batch_size//10 + 1))[:c.batch_size]).cuda()\n",
    "    test_cond = make_cond(test_labels).clone()\n",
    "\n",
    "try:\n",
    "    for i_epoch in range(-c.pre_low_lr, c.n_epochs):\n",
    "\n",
    "        loss_history = []\n",
    "        data_iter = iter(data.train_loader)\n",
    "\n",
    "        if i_epoch < 0:\n",
    "            for param_group in model.optim.param_groups:\n",
    "                param_group['lr'] = c.lr * 2e-2\n",
    "\n",
    "        for i_batch, data_tuple in tqdm.tqdm(enumerate(data_iter),\n",
    "                                              total=min(len(data.train_loader), c.n_its_per_epoch),\n",
    "                                              leave=False,\n",
    "                                              mininterval=1.,\n",
    "                                              disable=(not c.progress_bar),\n",
    "                                              ncols=83):\n",
    "\n",
    "            if c.colorize:\n",
    "                x, labels, masks = data_tuple\n",
    "                #print()\n",
    "                #print(x.shape, labels.shape, masks.shape, cond_tensor.shape)\n",
    "                #torch.Size([512, 3, 28, 28]) torch.Size([512]) torch.Size([512, 1, 28, 28]) torch.Size([512, 65])\n",
    "                x, labels, masks  = x.cuda(), labels.cuda(), masks.cuda()\n",
    "                x += c.add_image_noise * torch.cuda.FloatTensor(x.shape).normal_()\n",
    "                with torch.no_grad():\n",
    "                    cond_features = cond_net.model.features(masks)\n",
    "                    cond = make_cond(masks, cond_features)\n",
    "\n",
    "            else:\n",
    "                x, labels = data_tuple\n",
    "                x, labels = x.cuda(), labels.cuda()\n",
    "                x += c.add_image_noise * torch.cuda.FloatTensor(x.shape).normal_()\n",
    "\n",
    "                cond = make_cond(labels.cuda())\n",
    "\n",
    "            output = model.model(x, cond)\n",
    "\n",
    "            if c.do_fwd:\n",
    "                zz = torch.sum(output**2, dim=1)\n",
    "                jac = model.model.log_jacobian(run_forward=False)\n",
    "\n",
    "                neg_log_likeli = 0.5 * zz - jac\n",
    "\n",
    "                l = torch.mean(neg_log_likeli)\n",
    "                l.backward(retain_graph=c.do_rev)\n",
    "            else:\n",
    "                l = dummy_loss()\n",
    "\n",
    "            if c.do_rev:\n",
    "                samples_noisy = sample_outputs(c.latent_noise) + output.data\n",
    "\n",
    "                x_rec = model.model(samples_noisy, rev=True)\n",
    "                l_rev = torch.mean( (x-x_rec)**2 )\n",
    "                l_rev.backward()\n",
    "            else:\n",
    "                l_rev = dummy_loss()\n",
    "\n",
    "            model.optim_step()\n",
    "            loss_history.append([l.item(), l_rev.item()])\n",
    "\n",
    "            if i_batch+1 >= c.n_its_per_epoch:\n",
    "                # somehow the data loader workers don't shut down automatically\n",
    "                try:\n",
    "                    data_iter._shutdown_workers()\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                break\n",
    "\n",
    "        model.weight_scheduler.step()\n",
    "\n",
    "        epoch_losses = np.mean(np.array(loss_history), axis=0)\n",
    "        epoch_losses[0] = min(epoch_losses[0], 0)\n",
    "\n",
    "        if i_epoch > 1 - c.pre_low_lr:\n",
    "            viz.show_loss(epoch_losses, logscale=False)\n",
    "            output_orig = output.cpu()\n",
    "            viz.show_hist(output_orig)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            samples = sample_outputs(c.sampling_temperature)\n",
    "\n",
    "            if not c.colorize:\n",
    "                cond = test_cond\n",
    "\n",
    "            rev_imgs = model.model(samples, cond, rev=True)\n",
    "            ims = [rev_imgs]\n",
    "\n",
    "        viz.show_imgs(*list(data.unnormalize(i) for i in ims))\n",
    "\n",
    "        model.model.zero_grad()\n",
    "\n",
    "        if (i_epoch % c.checkpoint_save_interval) == 0:\n",
    "            model.save(c.filename + '_checkpoint_%.4i' % (i_epoch * (1-c.checkpoint_save_overwrite)))\n",
    "\n",
    "    model.save(c.filename)\n",
    "\n",
    "except:\n",
    "    if c.checkpoint_on_error:\n",
    "        model.save(c.filename + '_ABORT')\n",
    "\n",
    "    raise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6519ec3d6d74aa3a8a2f9552931a87abcc4f0825d19a87e9d6be02805cd5a20b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
